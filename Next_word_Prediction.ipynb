{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WVE4lTgZ94Ar"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import gutenberg\n",
        "from collections import defaultdict, Counter\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('gutenberg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP5FrCUq9-2X",
        "outputId": "cab31f95-66a4-47fe-d1cd-56bf86e1d82d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = gutenberg.raw(\"/content/1661-0.txt\")"
      ],
      "metadata": {
        "id": "Si66PsQp-Dnw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2JSJlmv-YjI",
        "outputId": "88500ecb-3eda-4ea5-d222-1d9d2ac94345"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(corpus)"
      ],
      "metadata": {
        "id": "IIyzcMwd-Sil"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freq_dict = defaultdict(Counter)"
      ],
      "metadata": {
        "id": "c8xqjA-q-l14"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(tokens) - 1):\n",
        "    word, next_word = tokens[i], tokens[i + 1]\n",
        "    freq_dict[word][next_word] += 1"
      ],
      "metadata": {
        "id": "DjFMWyNm-qKJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob_dict = defaultdict(dict)\n",
        "for word, next_words in freq_dict.items():\n",
        "    total = sum(next_words.values())\n",
        "    for next_word, count in next_words.items():\n",
        "        prob_dict[word][next_word] = count / total"
      ],
      "metadata": {
        "id": "mqh8cgph-uN2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_next_word(word):\n",
        "    next_words = prob_dict[word]\n",
        "    if len(next_words) == 0:\n",
        "        return None\n",
        "    return random.choices(list(next_words.keys()), list(next_words.values()))[0]"
      ],
      "metadata": {
        "id": "vW3NzPRZ-yI8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sentence(start_word, length=100):\n",
        "    sentence = [start_word]\n",
        "    for i in range(length):\n",
        "        next_word = generate_next_word(sentence[-1])\n",
        "        if next_word is None:\n",
        "            break\n",
        "        sentence.append(next_word)\n",
        "    return ' '.join(sentence)"
      ],
      "metadata": {
        "id": "tg6f2jt_-3Hl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_sentence('In', length=1000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONowrErR-8Eu",
        "outputId": "5a598975-2629-4a0e-ed86-0ed3ddfe28f2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In life than the features and what I should possess so much astonished , thereâs always as usual signal I deduced from death of his brains to insult me have some hunted animal lust for nothing which lay awake , though very easy in his safe from your Majesty , padlocked at the colonel fumbled about the original building , âthat this den of two days since breakfast.â VII . He wished to see the ground to be millions of Clark Russellâs fine theories and the suspicion there . It is quite epicurean little light and I fail , Lucy Parr , with great benefactor to the salesman nodded his fate as none , broad-brimmed hat drawn quite as freely as I will observe the window we shall be away the professional beggar , a suspicion . âWitness ( c , then ? â said I fancy that put there is a bulge on the small for you have to him . His brain is the handle and flapped and any rate.â She had been made the terms of papers here , and fastened ? â said he as he remarked , when suddenly bent over him , for to-morrow . He chuckled the matter before three rooms , for we have already a dozen other about our hands.â âJohn Clay serenely . Its owner of one which he realised how to befall . âThere is thought sometimes . âI do you look it cruel.â âI say his ring-finger , he was passing said that our little doubt or there ? â âExperience , and it upon my inheritance . We got the life has deprived me to interfere with him , for a violent start , Maggie ? â she died of us through which you have some small slip of a blow fell in the most solemn oaths which all day after she got to go about the country is swift in the wandering rather die for we broke out into convulsive sobbing , rather to avert another man might rely on the official detective in the King without a presumption that if he was never any violence . My niece ; and of the best . I glanced down a head that he was not been forced to his neighbour . But since as was elbowed away into the interview , with a sallow cheeks of honour and finally covered all that the thousands of his hand which was at Christmas dinner.â âDid I heard of this case against the fire was as I could have you best to your husband and carries it even persuaded myself . She became suspicious looks as if you beat . âYouâre angry that he perched himself , pushing her sleeves and after the cadaverous face . Of course , rose up among the fogs of the wedding ? â âShe told their tents , for âGesellschaft , when I can not quite clear that I jumped in forming an immediate access to the inspector . I shall certainly be more so kind . I have already deeply distrusted . His hand , during this bears upon my companion , in this way up to say that you are of that I fancy , upon the dim veil over with him a lunatic , with his right side of the table . You can be dust upon the scuffle without complying with sleepy porter with my town . Old Turner , themâs not notice , â âI know all ? There is a goose , â âThe best laid me to sit . âOh , where I could not be gained property . I set out at my friend , and hurried up the front of country which I should be compelled to see him for some future proceedings , with a long been so there a compilation copyright holder of Wilton carpet , but I see that somewhere . 1.E.6 . 1.F.5 . âWas she could earn into it he is the negroes , which I have called about , a little reputation among the extraordinary ? â said my witâs end what you nor the girlâs dress now been drawn my memory with pennies , it is too much faith of the other as well that his hand it out , of use.â âOh , âyou have clearer proofs before been for all clear to him yourselves , and there came for me in the fate of London in the matter becomes , really I was of the original `` Project Gutenberg EBook # 1661 ] Last Updated : âDEAR MR. HOLMES , only quote this bears upon the position in the stranger with fresh blood . I think that he was comparatively modern , when I thought of the tradesmenâs entrance . However , however , whatever it had a few minutesâ silence all , and without being terribly anxious look at the lantern and wedding ? â âAt half pounds in which is something akin to . âYou appeared to me remark the work with your address that anything of Baker , I must have my point.â He was important and fro like that the Crown.â âVery good drive away from eye for the results all was the hands in twenty minutes while poor little bald enough to speak calmly ; and that there jumped in the lawn of England a notice indicating that her mind about it isââ âThat was of the charm of the way for the wearer perspired very shiny , you received a little clearer . Once we have no difficulty in such a young man with his thick fog rolled in my mind anything which had he walked down there was gentle breathing now.â And now as I am all over the house more money , for this agreement shall be met our visitor , the case for purely nominal services . I can see me up the definite result . When ,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#In this code, we first load the data from the Gutenberg corpus and tokenize it using the word_tokenize function\n",
        "\n",
        "#from the NLTK library. We then create a dictionary to store the frequency of each word using the defaultdict and Counter\n",
        "\n",
        "#classes from the Python collections module.\n",
        "\n",
        "#Next, we generate the probability of the next word given the current word using the frequency dictionary.\n",
        "\n",
        "#We define a function generate_next_word to generate the next word given the current word based on the probability dictionary.\n",
        "\n",
        "#Finally, we define a function generate_sentence to generate a sentence by randomly selecting the next word based on  the probability of the next word given the current word. We generate a sentence by calling the generate_sentence function with a starting word and the length of the sentence.\n",
        "   "
      ],
      "metadata": {
        "id": "okOiqDeg_Flk"
      }
    }
  ]
}